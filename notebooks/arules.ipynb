{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../scripts/\")\n",
    "\n",
    "from utils import logger\n",
    "import metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "pd.set_option(\"mode.chained_assignment\", \"raise\")\n",
    "\n",
    "from scripts.first_stage_models.BaseModelv2 import BaseRecommenderv2\n",
    "\n",
    "attribute_name_key = \"attribute_name\"\n",
    "min_support_key = \"min_support_key\"\n",
    "item_id_column_key = \"item_id_column_key\"\n",
    "user_id_column_key = \"user_id_column_key\"\n",
    "items_key = \"items_key\"\n",
    "\n",
    "\n",
    "class ARulesRecommender(BaseRecommenderv2):\n",
    "    def __init__(self,\n",
    "                 config: dict,\n",
    "                 cold_items_recommender=None,\n",
    "                 int_article_id=None,\n",
    "                 int_customer_id=None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param config:\n",
    "        :param cold_items_recommender:\n",
    "        :param int_article_id:\n",
    "        :param int_customer_id:\n",
    "        \"\"\"\n",
    "        super().__init__(cold_items_recommender=cold_items_recommender,\n",
    "                         int_article_id=int_article_id,\n",
    "                         int_customer_id=int_customer_id)\n",
    "\n",
    "        self.config = config\n",
    "\n",
    "        self.encoder = None\n",
    "        self.frequent_itemsets = None\n",
    "        self.rules = None\n",
    "        self.previous_interactions = None\n",
    "\n",
    "    def _rename_duplicates(self, items: List[str]):\n",
    "        seen = set()\n",
    "        dupes = [item for item in items if item in seen or seen.add(item)]\n",
    "        renamed_items = [item + \"_dup\" for item in dupes]\n",
    "        return list(set(items + renamed_items))\n",
    "\n",
    "    def _interactions_to_item_lists(self, interactions: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a list of items for each user\n",
    "        :param interactions:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        grouped_interactions = interactions.groupby(by=[self.config[user_id_column_key]])[\n",
    "            [self.config[attribute_name_key]]].agg(list).reset_index()\n",
    "\n",
    "        grouped_interactions.loc[:, self.config[attribute_name_key]] = grouped_interactions[\n",
    "            self.config[attribute_name_key]].apply(\n",
    "            self._rename_duplicates)\n",
    "        return grouped_interactions\n",
    "\n",
    "    def _association_rules_analysis(self, user_item_lists: pd.DataFrame):\n",
    "        encoder = TransactionEncoder()\n",
    "        interaction_matrix = encoder.fit_transform(user_item_lists[self.config[attribute_name_key]])\n",
    "        df = pd.DataFrame(interaction_matrix, columns=encoder.columns_)\n",
    "\n",
    "        frequent_itemsets = fpgrowth(df,\n",
    "                                     min_support=self.config[min_support_key],\n",
    "                                     use_colnames=True,\n",
    "                                     max_len=10)\n",
    "        rules = association_rules(frequent_itemsets,\n",
    "                                  metric=\"confidence\",\n",
    "                                  min_threshold=self.config[min_support_key])\n",
    "        return frequent_itemsets, rules, encoder\n",
    "\n",
    "    def _recommend_items(self, previous_user_items):\n",
    "        # TODO: fix const = 30\n",
    "        tmp = self.rules[self.rules['antecedents'].apply(lambda x: x.issubset(previous_user_items))][\n",
    "                  \"consequents\"].drop_duplicates().tolist()[:20]\n",
    "        result = list(set().union(*tmp))[:12]\n",
    "        return result\n",
    "\n",
    "    def _predict(self,\n",
    "                customers: list,\n",
    "                top_k: int = 12) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Make predictions for c in customers which were  presented in train  interactions\n",
    "        :param customers:\n",
    "        :param top_k:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        previous_interactions = self.previous_interactions[\n",
    "            self.previous_interactions[self.config[user_id_column_key]].isin(customers)]\n",
    "\n",
    "        predictions = self._interactions_to_item_lists(previous_interactions)\n",
    "        predictions[\"predicted_ids\"] = predictions[self.config[attribute_name_key]].apply(\n",
    "            self._recommend_items)\n",
    "        predictions = predictions.rename(columns={config[item_id_column_key]: \"previous_ids\"})\n",
    "        predictions[\"predicted_ids\"] = predictions[\"predicted_ids\"].apply(lambda x: [int(xi.split('_')[0]) for xi in x])\n",
    "        predictions[\"predicted_ids\"] = predictions[\"predicted_ids\"].apply(lambda x: x[:top_k])\n",
    "        predictions = predictions[predictions.predicted_ids.apply(len)>0]\n",
    "        predictions[\"score\"] = 1\n",
    "        return predictions\n",
    "\n",
    "    def fit(self, interactions: pd.DataFrame):\n",
    "        interactions = interactions.copy()\n",
    "        items = self.config[items_key]\n",
    "        interactions.loc[:, self.config[attribute_name_key]] = interactions.loc[:, self.config[attribute_name_key]].astype(str)\n",
    "        if self.config[item_id_column_key] != self.config[attribute_name_key]:\n",
    "            interactions = interactions.merge(items[[self.config[item_id_column_key], self.config[attribute_name_key]]],\n",
    "                                              on=self.config[item_id_column_key],\n",
    "                                              how=\"left\")\n",
    "        user_item_lists = self._interactions_to_item_lists(interactions)\n",
    "        frequent_itemsets, rules, encoder = self._association_rules_analysis(user_item_lists)\n",
    "        self.encoder = encoder\n",
    "        self.frequent_itemsets = frequent_itemsets\n",
    "        self.rules = rules\n",
    "        self.previous_interactions = interactions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from typing import List\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, tqdm_notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "sns.set()\n",
    "plt.rcParams['figure.figsize'] = [10, 4]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "pd.options.display.max_rows = 50\n",
    "pd.options.display.max_columns = 50\n",
    "np.set_printoptions(edgeitems=10)\n",
    "np.core.arrayprint._line_width = 500\n",
    "pd.set_option('display.width', 1000)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "transactions = pd.read_parquet('../data/compressed_dataset/transactions.parquet')\n",
    "articles = pd.read_parquet('../data/compressed_dataset/articles.parquet')\n",
    "customers = pd.read_parquet('../data/compressed_dataset/customers.parquet')\n",
    "\n",
    "article_id_int = pd.read_pickle('../data/compressed_dataset/article_id_int.pickle')\n",
    "int_article_id = pd.read_pickle('../data/compressed_dataset/int_article_id.pickle')\n",
    "\n",
    "customer_id_int = pd.read_pickle('../data/compressed_dataset/customer_id_int.pickle')\n",
    "int_customer_id = pd.read_pickle('../data/compressed_dataset/int_customer_id.pickle')\n",
    "\n",
    "transactions[\"t_dat\"] = pd.to_datetime(transactions[\"t_dat\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Association Rules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def split_transactions(transactions: pd.DataFrame,\n",
    "                       assessed_date: pd.Timestamp,\n",
    "                       history_size_days: int\n",
    "                       ):\n",
    "    \"\"\"\n",
    "    Split all transaction into two parts:\n",
    "    train_transactions - [assessed_date - history_size_days, assesed_days)\n",
    "    test_transactions - [assessed_date, assessed_date + 6d]\n",
    "    :param transactions:\n",
    "    :param assessed_date:\n",
    "    :param history_size_days:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_test_date = assessed_date + pd.Timedelta(\"6d\")\n",
    "    min_train_date = assessed_date - pd.Timedelta(f\"{history_size_days}d\")\n",
    "    test_transactions = transactions[\n",
    "        (transactions[\"t_dat\"] >= assessed_date) &\n",
    "        (transactions[\"t_dat\"] <= max_test_date)]\n",
    "    train_transactions = transactions[\n",
    "        (transactions[\"t_dat\"] >= min_train_date) &\n",
    "        (transactions[\"t_dat\"] < assessed_date)]\n",
    "    return train_transactions, test_transactions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "assessed_date = transactions[\"t_dat\"].max() - pd.Timedelta(\"12d\")\n",
    "train_transactions, test_transactions = split_transactions(transactions,\n",
    "                                                           assessed_date,\n",
    "                                                           history_size_days=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train_transactions =  193917\n",
      "n_test_transactions =  240643\n"
     ]
    }
   ],
   "source": [
    "print(\"n_train_transactions = \", len(train_transactions))\n",
    "print(\"n_test_transactions = \", len(test_transactions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-05 00:00:00 2020-09-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(train_transactions[\"t_dat\"].min(), train_transactions[\"t_dat\"].max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-10 00:00:00 2020-09-16 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(test_transactions[\"t_dat\"].min(), test_transactions[\"t_dat\"].max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       antecedents   consequents  antecedent support  consequent support   support  confidence         lift  leverage  conviction\n0         (104157)       (17134)            0.004375            0.001882  0.000161    0.036885    19.593794  0.000153    1.036343\n1          (17134)      (104157)            0.001882            0.004375  0.000161    0.085714    19.593794  0.000153    1.088965\n2           (3091)       (17134)            0.006741            0.001882  0.000143    0.021277    11.302330  0.000131    1.019816\n3          (17134)        (3091)            0.001882            0.006741  0.000143    0.076190    11.302330  0.000131    1.075177\n4         (105258)      (103303)            0.004984            0.003406  0.000108    0.021583     6.335895  0.000091    1.018577\n...            ...           ...                 ...                 ...       ...         ...          ...       ...         ...\n8545  (100418_dup)      (100418)            0.000108            0.000502  0.000108    1.000000  1992.035714  0.000108         inf\n8546  (103557_dup)      (103557)            0.000108            0.000843  0.000108    1.000000  1186.744681  0.000107         inf\n8547      (103557)  (103557_dup)            0.000843            0.000108  0.000108    0.127660  1186.744681  0.000107    1.146218\n8548       (66517)   (66517_dup)            0.001614            0.000108  0.000108    0.066667   619.744444  0.000107    1.071313\n8549   (66517_dup)       (66517)            0.000108            0.001614  0.000108    1.000000   619.744444  0.000107         inf\n\n[8550 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>antecedents</th>\n      <th>consequents</th>\n      <th>antecedent support</th>\n      <th>consequent support</th>\n      <th>support</th>\n      <th>confidence</th>\n      <th>lift</th>\n      <th>leverage</th>\n      <th>conviction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(104157)</td>\n      <td>(17134)</td>\n      <td>0.004375</td>\n      <td>0.001882</td>\n      <td>0.000161</td>\n      <td>0.036885</td>\n      <td>19.593794</td>\n      <td>0.000153</td>\n      <td>1.036343</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(17134)</td>\n      <td>(104157)</td>\n      <td>0.001882</td>\n      <td>0.004375</td>\n      <td>0.000161</td>\n      <td>0.085714</td>\n      <td>19.593794</td>\n      <td>0.000153</td>\n      <td>1.088965</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(3091)</td>\n      <td>(17134)</td>\n      <td>0.006741</td>\n      <td>0.001882</td>\n      <td>0.000143</td>\n      <td>0.021277</td>\n      <td>11.302330</td>\n      <td>0.000131</td>\n      <td>1.019816</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(17134)</td>\n      <td>(3091)</td>\n      <td>0.001882</td>\n      <td>0.006741</td>\n      <td>0.000143</td>\n      <td>0.076190</td>\n      <td>11.302330</td>\n      <td>0.000131</td>\n      <td>1.075177</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(105258)</td>\n      <td>(103303)</td>\n      <td>0.004984</td>\n      <td>0.003406</td>\n      <td>0.000108</td>\n      <td>0.021583</td>\n      <td>6.335895</td>\n      <td>0.000091</td>\n      <td>1.018577</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8545</th>\n      <td>(100418_dup)</td>\n      <td>(100418)</td>\n      <td>0.000108</td>\n      <td>0.000502</td>\n      <td>0.000108</td>\n      <td>1.000000</td>\n      <td>1992.035714</td>\n      <td>0.000108</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>8546</th>\n      <td>(103557_dup)</td>\n      <td>(103557)</td>\n      <td>0.000108</td>\n      <td>0.000843</td>\n      <td>0.000108</td>\n      <td>1.000000</td>\n      <td>1186.744681</td>\n      <td>0.000107</td>\n      <td>inf</td>\n    </tr>\n    <tr>\n      <th>8547</th>\n      <td>(103557)</td>\n      <td>(103557_dup)</td>\n      <td>0.000843</td>\n      <td>0.000108</td>\n      <td>0.000108</td>\n      <td>0.127660</td>\n      <td>1186.744681</td>\n      <td>0.000107</td>\n      <td>1.146218</td>\n    </tr>\n    <tr>\n      <th>8548</th>\n      <td>(66517)</td>\n      <td>(66517_dup)</td>\n      <td>0.001614</td>\n      <td>0.000108</td>\n      <td>0.000108</td>\n      <td>0.066667</td>\n      <td>619.744444</td>\n      <td>0.000107</td>\n      <td>1.071313</td>\n    </tr>\n    <tr>\n      <th>8549</th>\n      <td>(66517_dup)</td>\n      <td>(66517)</td>\n      <td>0.000108</td>\n      <td>0.001614</td>\n      <td>0.000108</td>\n      <td>1.000000</td>\n      <td>619.744444</td>\n      <td>0.000107</td>\n      <td>inf</td>\n    </tr>\n  </tbody>\n</table>\n<p>8550 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    attribute_name_key: \"article_id\",\n",
    "    min_support_key: 0.0001,\n",
    "    item_id_column_key: \"article_id\",\n",
    "    user_id_column_key: \"customer_id\",\n",
    "    items_key: articles\n",
    "}\n",
    "recommender = ARulesRecommender(config)\n",
    "recommender.fit(train_transactions)\n",
    "recommender.rules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       customer_id                                       previous_ids                                      predicted_ids  score\n0               38            [100027, 104448, 105273, 103170, 17134]  [17125, 105274, 3091, 17132, 104157, 104155, 1...      1\n2              327                [66525, 80304, 69749, 80298, 70911]  [99655, 25799, 70911, 70916, 105179, 66517, 94...      1\n4              402                     [85058, 105181, 70640, 105179]  [104986, 105258, 105179, 105181, 105306, 70911...      1\n5              527  [105306, 103791_dup, 105306_dup, 103791, 10176...  [103186, 105179, 105181, 105306, 105306, 10548...      1\n6              919       [97918, 101279, 93738, 71106, 105270, 98987]  [71101, 105270, 99398, 100282, 104434, 101278,...      1\n...            ...                                                ...                                                ...    ...\n10375      1370855                                     [90436, 99254]                              [93370, 99254, 99255]      1\n10376      1371336          [100162_dup, 43705, 43701, 100162, 97520]  [43711, 43695, 43705, 94657, 43701, 43708, 975...      1\n10378      1371462                                     [7762, 103668]  [103669, 103667, 53914, 103670, 103665, 53892,...      1\n10380      1371691   [104157, 104192_dup, 104192, 104193_dup, 104193]  [17125, 97251, 101192, 98237, 53896, 104434, 1...      1\n10382      1371960  [102628, 103304, 102628_dup, 97246, 80932, 990...  [94697, 104434, 103303, 94696, 94698, 103302, ...      1\n\n[7422 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>previous_ids</th>\n      <th>predicted_ids</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>38</td>\n      <td>[100027, 104448, 105273, 103170, 17134]</td>\n      <td>[17125, 105274, 3091, 17132, 104157, 104155, 1...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>327</td>\n      <td>[66525, 80304, 69749, 80298, 70911]</td>\n      <td>[99655, 25799, 70911, 70916, 105179, 66517, 94...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>402</td>\n      <td>[85058, 105181, 70640, 105179]</td>\n      <td>[104986, 105258, 105179, 105181, 105306, 70911...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>527</td>\n      <td>[105306, 103791_dup, 105306_dup, 103791, 10176...</td>\n      <td>[103186, 105179, 105181, 105306, 105306, 10548...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>919</td>\n      <td>[97918, 101279, 93738, 71106, 105270, 98987]</td>\n      <td>[71101, 105270, 99398, 100282, 104434, 101278,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10375</th>\n      <td>1370855</td>\n      <td>[90436, 99254]</td>\n      <td>[93370, 99254, 99255]</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10376</th>\n      <td>1371336</td>\n      <td>[100162_dup, 43705, 43701, 100162, 97520]</td>\n      <td>[43711, 43695, 43705, 94657, 43701, 43708, 975...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10378</th>\n      <td>1371462</td>\n      <td>[7762, 103668]</td>\n      <td>[103669, 103667, 53914, 103670, 103665, 53892,...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10380</th>\n      <td>1371691</td>\n      <td>[104157, 104192_dup, 104192, 104193_dup, 104193]</td>\n      <td>[17125, 97251, 101192, 98237, 53896, 104434, 1...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10382</th>\n      <td>1371960</td>\n      <td>[102628, 103304, 102628_dup, 97246, 80932, 990...</td>\n      <td>[94697, 104434, 103303, 94696, 94698, 103302, ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>7422 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_customers = list(test_transactions.customer_id.unique())\n",
    "predictions = recommender.predict(customers=test_customers)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def average_prec(true, pred):\n",
    "    n_correct_items = 0.0\n",
    "    score = 0.0\n",
    "    for k, pred_item in enumerate(pred):\n",
    "        if pred_item in true:\n",
    "            n_correct_items += 1\n",
    "            prec_k = n_correct_items / (k + 1)\n",
    "            score += prec_k\n",
    "    return score / len(pred)\n",
    "\n",
    "\n",
    "def mean_average_prec(true, pred):\n",
    "    assert len(true) == len(pred), \"Different number of users\"\n",
    "    n = 0\n",
    "    score = 0.0\n",
    "    for true_items, pred_items in tqdm(list(zip(true, pred))):\n",
    "        if len(true_items) > 0:\n",
    "            score += average_prec(true_items, pred_items)\n",
    "            n += 1\n",
    "    print('users with purchases = ', n)\n",
    "    return score / n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "      customer_id                              true_article_ids                                       previous_ids                                      predicted_ids\n0              38                                       [61916]            [100027, 104448, 105273, 103170, 17134]  [17125, 105274, 3091, 17132, 104157, 104155, 1...\n1             327                                [98445, 98445]                [66525, 80304, 69749, 80298, 70911]  [99655, 25799, 70911, 70916, 105179, 66517, 94...\n2             402                              [100947, 102939]                     [85058, 105181, 70640, 105179]  [104986, 105258, 105179, 105181, 105306, 70911...\n3             527                              [104215, 103156]  [105306, 103791_dup, 105306_dup, 103791, 10176...  [103186, 105179, 105181, 105306, 105306, 10548...\n4             919                                      [104372]       [97918, 101279, 93738, 71106, 105270, 98987]  [71101, 105270, 99398, 100282, 104434, 101278,...\n...           ...                                           ...                                                ...                                                ...\n7417      1370855                                       [90436]                                     [90436, 99254]                              [93370, 99254, 99255]\n7418      1371336                               [100162, 75213]          [100162_dup, 43705, 43701, 100162, 97520]  [43711, 43695, 43705, 94657, 43701, 43708, 975...\n7419      1371462                                        [7762]                                     [7762, 103668]  [103669, 103667, 53914, 103670, 103665, 53892,...\n7420      1371691  [104157, 104157, 104157, 87698, 2480, 82631]   [104157, 104192_dup, 104192, 104193_dup, 104193]  [17125, 97251, 101192, 98237, 53896, 104434, 1...\n7421      1371960                                [66500, 99010]  [102628, 103304, 102628_dup, 97246, 80932, 990...  [94697, 104434, 103303, 94696, 94698, 103302, ...\n\n[7422 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>customer_id</th>\n      <th>true_article_ids</th>\n      <th>previous_ids</th>\n      <th>predicted_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>38</td>\n      <td>[61916]</td>\n      <td>[100027, 104448, 105273, 103170, 17134]</td>\n      <td>[17125, 105274, 3091, 17132, 104157, 104155, 1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>327</td>\n      <td>[98445, 98445]</td>\n      <td>[66525, 80304, 69749, 80298, 70911]</td>\n      <td>[99655, 25799, 70911, 70916, 105179, 66517, 94...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>402</td>\n      <td>[100947, 102939]</td>\n      <td>[85058, 105181, 70640, 105179]</td>\n      <td>[104986, 105258, 105179, 105181, 105306, 70911...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>527</td>\n      <td>[104215, 103156]</td>\n      <td>[105306, 103791_dup, 105306_dup, 103791, 10176...</td>\n      <td>[103186, 105179, 105181, 105306, 105306, 10548...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>919</td>\n      <td>[104372]</td>\n      <td>[97918, 101279, 93738, 71106, 105270, 98987]</td>\n      <td>[71101, 105270, 99398, 100282, 104434, 101278,...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7417</th>\n      <td>1370855</td>\n      <td>[90436]</td>\n      <td>[90436, 99254]</td>\n      <td>[93370, 99254, 99255]</td>\n    </tr>\n    <tr>\n      <th>7418</th>\n      <td>1371336</td>\n      <td>[100162, 75213]</td>\n      <td>[100162_dup, 43705, 43701, 100162, 97520]</td>\n      <td>[43711, 43695, 43705, 94657, 43701, 43708, 975...</td>\n    </tr>\n    <tr>\n      <th>7419</th>\n      <td>1371462</td>\n      <td>[7762]</td>\n      <td>[7762, 103668]</td>\n      <td>[103669, 103667, 53914, 103670, 103665, 53892,...</td>\n    </tr>\n    <tr>\n      <th>7420</th>\n      <td>1371691</td>\n      <td>[104157, 104157, 104157, 87698, 2480, 82631]</td>\n      <td>[104157, 104192_dup, 104192, 104193_dup, 104193]</td>\n      <td>[17125, 97251, 101192, 98237, 53896, 104434, 1...</td>\n    </tr>\n    <tr>\n      <th>7421</th>\n      <td>1371960</td>\n      <td>[66500, 99010]</td>\n      <td>[102628, 103304, 102628_dup, 97246, 80932, 990...</td>\n      <td>[94697, 104434, 103303, 94696, 94698, 103302, ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>7422 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_items = test_transactions.groupby(by=\"customer_id\")[\"article_id\"].agg(list).reset_index().rename(\n",
    "    columns={\"article_id\": \"true_article_ids\"}\n",
    ")\n",
    "true_items[\"true_ids\"] = true_items[\"true_article_ids\"].apply(lambda x: x[:12])\n",
    "df = true_items.merge(predictions, on=\"customer_id\")[\n",
    "    [\"customer_id\", \"true_article_ids\", \"previous_ids\", \"predicted_ids\"]]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7422/7422 [00:00<00:00, 354117.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users with purchases =  7422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.03056040177816023"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_prec(df[\"true_article_ids\"].tolist(),\n",
    "                  df[\"predicted_ids\"].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Try to include all users (last 5 transactions (or maybe more if they were within short period of time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def split_transactions2(transactions: pd.DataFrame,\n",
    "                       assessed_date: pd.Timestamp,\n",
    "                       last_interactions_n\n",
    "                       ):\n",
    "    \"\"\"\n",
    "    Split all transaction into two parts:\n",
    "    train_transactions - [assessed_date - history_size_days, assesed_days)\n",
    "    test_transactions - [assessed_date, assessed_date + 6d]\n",
    "    :param transactions:\n",
    "    :param assessed_date:\n",
    "    :param history_size_days:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    max_test_date = assessed_date + pd.Timedelta(\"6d\")\n",
    "    test_transactions = transactions[\n",
    "        (transactions[\"t_dat\"] >= assessed_date) &\n",
    "        (transactions[\"t_dat\"] <= max_test_date)]\n",
    "    train_transactions = transactions[\n",
    "        transactions[\"t_dat\"] < assessed_date]\n",
    "    train_transactions = train_transactions.sort_values(by = [\"customer_id\", \"t_dat\"]).groupby(by=\"customer_id\").head(last_interactions_n)\n",
    "    return train_transactions, test_transactions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "assessed_date = transactions[\"t_dat\"].max() - pd.Timedelta(\"6d\")\n",
    "train_transactions, test_transactions = split_transactions2(transactions,\n",
    "                                                           assessed_date,\n",
    "                                                           5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "config = {\n",
    "    attribute_name_key: \"article_id\",\n",
    "    min_support_key: 0.001,\n",
    "    item_id_column_key: \"article_id\",\n",
    "    user_id_column_key: \"customer_id\",\n",
    "    items_key: articles\n",
    "}\n",
    "recommender = ARulesRecommender(config)\n",
    "recommender.fit(train_transactions)\n",
    "recommender.rules"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_customers = list(test_transactions.customer_id.unique())\n",
    "predictions = recommender.predict(customers=test_customers)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_items = test_transactions.groupby(by=\"customer_id\")[\"article_id\"].agg(list).reset_index().rename(\n",
    "    columns={\"article_id\": \"true_article_ids\"}\n",
    ")\n",
    "true_items[\"true_ids\"] = true_items[\"true_article_ids\"].apply(lambda x: x[:12])\n",
    "df = true_items.merge(predictions, on=\"customer_id\")[\n",
    "    [\"customer_id\", \"true_article_ids\", \"previous_ids\", \"predicted_ids\"]]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_average_prec(df[\"true_article_ids\"].tolist(),\n",
    "                  df[\"predicted_ids\"].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}